{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part-of-Speech tagging of Code-Mixed Social Media Text\n",
    "\n",
    "\n",
    "A program to tag Parts Of Speech on code-mixed data from http://www.amitavadas.com/Code-Mixing.html competition which consisted of Bengali-English, Hindi-English, Telugu_English code mixed texts.\n",
    "We have extracted n-gram features, neighboring words and language to train a 3 CRF models. Achieved an F1_score of 0.79,0.79,0.71 for Bengali, Hindi and Telugu respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################\n",
    "\n",
    "Task at hand : POS tagging on Code Mixed Text \n",
    "\n",
    "\n",
    "Input Data : Text with Language and POS tags \n",
    "\n",
    "##########################################\n",
    "\n",
    "Features usec : 1 - 5 grams + Language + Next word + Previous word + Beginning of Sentence + End of Sentence\n",
    "\n",
    "Model Selected : Conditional Random Fields (CRF)\n",
    "\n",
    "Parameters\n",
    "    \n",
    "    Algirithm : L-BFGS - Gradient descent using the L-BFGS method\n",
    "    'c1': 0.09\n",
    "    'c2': 0.50\n",
    "    \n",
    "##########################################\n",
    "\n",
    "Accuracy Measure \n",
    "\n",
    "F1_score \n",
    "\n",
    "    BENGALI - ENGLISH\n",
    "    Micro : 0.79\n",
    "    Macro : 0.68\n",
    "    Weighted : 0.78\n",
    "    \n",
    "    HINDI - ENGLISH\n",
    "    Micro : 0.79\n",
    "    Macro : 0.75\n",
    "    Weighted : 0.79\n",
    "    \n",
    "    TELUGU - ENGLISH\n",
    "    Micro : 0.71\n",
    "    Macro : 0.63\n",
    "    Weighted : 0.71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn\n",
    "import pycrfsuite\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files):\n",
    "    data, sent = [], []\n",
    "    for file in files:\n",
    "        with open(file, 'r') as rf:\n",
    "            for line in rf:\n",
    "                if line.strip() != '':\n",
    "                    # Note: the shared corpus is already tokenized\n",
    "                    sent.append(line.strip().split('\\t'))\n",
    "                else:\n",
    "                    if len(sent) > 0:\n",
    "                        data.append(sent)\n",
    "                        sent = []\n",
    "    return data\n",
    "\n",
    "sents_BN = load_data(['data/FB_BN_EN_CR.txt', 'data/TWT_BN_EN_CR.txt', 'data/WA_BN_EN_CR.txt'])\n",
    "sents_HI = load_data(['data/FB_HI_EN_CR.txt', 'data/TWT_HI_EN_CR.txt', 'data/WA_HI_EN_CR.txt'])\n",
    "sents_TE = load_data(['data/FB_TE_EN_CR.txt', 'data/TWT_TE_EN_CR.txt', 'data/WA_TE_EN_CR.txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train sentences for BENGALI-ENGLISH: 499\n",
      "# Validation sentences for BENGALI-ENGLISH: 125\n",
      "# Train sentences for HINDI-ENGLISH: 2104\n",
      "# Validation sentences for HINDI-ENGLISH: 526\n",
      "# Train sentences for TELUGU-ENGLISH: 1583\n",
      "# Validation sentences for TELUGU-ENGLISH: 396\n"
     ]
    }
   ],
   "source": [
    "random.seed(7)\n",
    "random.shuffle(sents_BN)\n",
    "random.shuffle(sents_HI)\n",
    "random.shuffle(sents_TE)\n",
    "train_sents_BN = sents_BN[:int(0.8*len(sents_BN))]\n",
    "valid_sents_BN = sents_BN[int(0.8*len(sents_BN)):]\n",
    "train_sents_HI = sents_HI[:int(0.8*len(sents_HI))]\n",
    "valid_sents_HI = sents_HI[int(0.8*len(sents_HI)):]\n",
    "train_sents_TE = sents_TE[:int(0.8*len(sents_TE))]\n",
    "valid_sents_TE = sents_TE[int(0.8*len(sents_TE)):]\n",
    "print(\"# Train sentences for BENGALI-ENGLISH: %d\" % (len(train_sents_BN)))\n",
    "print(\"# Validation sentences for BENGALI-ENGLISH: %d\" % (len(valid_sents_BN)))\n",
    "print(\"# Train sentences for HINDI-ENGLISH: %d\" % (len(train_sents_HI)))\n",
    "print(\"# Validation sentences for HINDI-ENGLISH: %d\" % (len(valid_sents_HI)))\n",
    "print(\"# Train sentences for TELUGU-ENGLISH: %d\" % (len(train_sents_TE)))\n",
    "print(\"# Validation sentences for TELUGU-ENGLISH: %d\" % (len(valid_sents_TE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "N - gram vectors : 1 - 5\n",
    "\n",
    "Language extraction\n",
    "\n",
    "End of Sentence\n",
    "\n",
    "Begining of Sentence\n",
    "\n",
    "Next word\n",
    "\n",
    "Previous word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2langs(sent):\n",
    "    return [language_label for token, language_label, pos_tag in sent]\n",
    "\n",
    "def word2features(sent, k):\n",
    "    \n",
    "    word = sent[k][0]\n",
    "    features = [\n",
    "        'token=%s' % (word)\n",
    "    ]\n",
    "    \n",
    "    lang = sent[k][1]\n",
    "    features.append(lang)\n",
    "    \n",
    "    # extracting n-grams, for n=1 to 5\n",
    "    for i in range(1,6):\n",
    "        # if the value of n is greater than the word length, we exit the loop\n",
    "        if i > len(word):\n",
    "            break\n",
    "        character_features = [word[j:j+i] for j in range(len(word)-i+1)]\n",
    "        features.extend([\n",
    "            # is count of individual n-grams important? is the order important?\n",
    "            \"char-%d-gram=%s\" % (i, ' '.join(list(set(character_features))))\n",
    "        ])\n",
    "    if k == 0:\n",
    "        # first word in the sentence\n",
    "        features.append('BOS')\n",
    "    else:\n",
    "        features.extend([\n",
    "            \"-1:word=%s\" % (sent[k-1][0])\n",
    "        ])\n",
    "    if k == (len(sent)-1):\n",
    "        # last word in the sentence         \n",
    "        features.append('EOS')\n",
    "    else:\n",
    "        features.extend([\n",
    "            \"+1:word=%s\" % (sent[k+1][0])\n",
    "        ])\n",
    " \n",
    "    return features\n",
    "        \n",
    "def sent2features(sent):\n",
    "    # generating features for all the words/tokens in a sentence `sent`    \n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "\n",
    "def sent2pos(sent):\n",
    "    return [pos_tag for token, language_label, pos_tag in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, language_label, pos_tag in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BENGALI-ENGLISH\n",
    "X_train_BN = [sent2features(sent) for sent in train_sents_BN]\n",
    "y_train_BN = [sent2pos(sent) for sent in train_sents_BN]\n",
    "\n",
    "X_test_BN = [sent2features(sent) for sent in valid_sents_BN]\n",
    "y_test_BN = [sent2pos(sent) for sent in valid_sents_BN]\n",
    "\n",
    "\n",
    "##HINDI-ENGLISH\n",
    "X_train_HI = [sent2features(sent) for sent in train_sents_HI]\n",
    "y_train_HI = [sent2pos(sent) for sent in train_sents_HI]\n",
    "\n",
    "X_test_HI = [sent2features(sent) for sent in valid_sents_HI]\n",
    "y_test_HI = [sent2pos(sent) for sent in valid_sents_HI]\n",
    "\n",
    "\n",
    "##HINDI-ENGLISH\n",
    "X_train_TE = [sent2features(sent) for sent in train_sents_TE]\n",
    "y_train_TE = [sent2pos(sent) for sent in train_sents_TE]\n",
    "\n",
    "X_test_TE = [sent2features(sent) for sent in valid_sents_TE]\n",
    "y_test_TE = [sent2pos(sent) for sent in valid_sents_TE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bengali-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#BENGALI\n",
    "trainer_BN = pycrfsuite.Trainer(algorithm='lbfgs', verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_BN, y_train_BN):\n",
    "    trainer_BN.append(xseq, yseq)\n",
    "    \n",
    "trainer_BN.set_params({\n",
    "    'c1': 0.09,   # coefficient for L1 penalty\n",
    "    'c2': 0.50,  # coefficient for L2 penalty\n",
    "    'max_iterations': 1000,  # stop earlier\n",
    "    'linesearch' : 'StrongBacktracking',\n",
    "    'num_memories' : 15,\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})    \n",
    "    \n",
    "display(trainer_BN.params())\n",
    "\n",
    "trainer_BN.train('BN.crfsuite')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#HINDI\n",
    "trainer_HI = pycrfsuite.Trainer(algorithm='lbfgs', verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_HI, y_train_HI):\n",
    "    trainer_HI.append(xseq, yseq)\n",
    "    \n",
    "trainer_HI.set_params({\n",
    "    'c1': 0.09,   # coefficient for L1 penalty\n",
    "    'c2': 0.50,  # coefficient for L2 penalty\n",
    "    'max_iterations': 1000,  # stop earlier\n",
    "    'linesearch' : 'StrongBacktracking',\n",
    "    'num_memories' : 15,\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})    \n",
    "    \n",
    "display(trainer_HI.params())\n",
    "\n",
    "trainer_HI.train('HI.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telugu-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature.minfreq',\n",
       " 'feature.possible_states',\n",
       " 'feature.possible_transitions',\n",
       " 'c1',\n",
       " 'c2',\n",
       " 'max_iterations',\n",
       " 'num_memories',\n",
       " 'epsilon',\n",
       " 'period',\n",
       " 'delta',\n",
       " 'linesearch',\n",
       " 'max_linesearch']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TELUGU\n",
    "trainer_TE = pycrfsuite.Trainer(algorithm='lbfgs', verbose=False)\n",
    "\n",
    "for xseq, yseq in zip(X_train_TE, y_train_TE):\n",
    "    trainer_TE.append(xseq, yseq)\n",
    "    \n",
    "trainer_TE.set_params({\n",
    "    'c1': 0.09,   # coefficient for L1 penalty\n",
    "    'c2': 0.50,  # coefficient for L2 penalty\n",
    "    'max_iterations': 1000,  # stop earlier\n",
    "    'linesearch' : 'StrongBacktracking',\n",
    "    'num_memories' : 15,\n",
    "\n",
    "    # include transitions that are possible, but not observed\n",
    "    'feature.possible_transitions': True\n",
    "})    \n",
    "    \n",
    "display(trainer_TE.params())\n",
    "\n",
    "trainer_TE.train('TE.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bengali-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.83      0.91      0.87        33\n",
      "           $       1.00      0.43      0.60        21\n",
      "           @       0.94      0.83      0.88        41\n",
      "          CC       0.93      0.76      0.84        68\n",
      "          DT       1.00      0.70      0.82        33\n",
      "           E       0.69      0.50      0.58        18\n",
      "         G_J       0.84      0.54      0.66       137\n",
      "         G_N       0.72      0.92      0.81      1072\n",
      "       G_PRP       0.82      0.82      0.82       286\n",
      "       G_PRT       0.74      0.49      0.59       102\n",
      "         G_R       0.73      0.43      0.54        89\n",
      "       G_SYM       0.64      0.47      0.54        60\n",
      "         G_V       0.78      0.64      0.70       424\n",
      "         G_X       0.98      0.89      0.93       463\n",
      "         PSP       0.76      0.74      0.75       207\n",
      "           U       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      3056\n",
      "   macro avg       0.77      0.63      0.68      3056\n",
      "weighted avg       0.80      0.79      0.78      3056\n",
      " samples avg       0.79      0.79      0.79      3056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MrVarma/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('BN.crfsuite')\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "\n",
    "y_pred_BN = [tagger.tag(xseq) for xseq in X_test_BN]\n",
    "\n",
    "\n",
    "print(bio_classification_report(y_test_BN, y_pred_BN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hindi-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.85      0.64      0.73       121\n",
      "           $       0.82      0.53      0.64        70\n",
      "           @       0.70      0.95      0.80       222\n",
      "          CC       0.71      0.54      0.62       136\n",
      "          DT       0.92      0.86      0.88       269\n",
      "           E       0.78      0.78      0.78        58\n",
      "         G_J       0.74      0.52      0.61       382\n",
      "         G_N       0.74      0.90      0.81      2421\n",
      "       G_PRP       0.85      0.80      0.82       604\n",
      "       G_PRT       0.65      0.52      0.58       242\n",
      "         G_R       0.89      0.74      0.81       265\n",
      "       G_SYM       0.74      0.53      0.62        60\n",
      "         G_V       0.83      0.75      0.79      1271\n",
      "         G_X       0.90      0.85      0.88      1185\n",
      "         PSP       0.80      0.70      0.75       475\n",
      "           U       0.71      0.72      0.71        57\n",
      "           ~       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      7848\n",
      "   macro avg       0.80      0.73      0.75      7848\n",
      "weighted avg       0.80      0.79      0.79      7848\n",
      " samples avg       0.79      0.79      0.79      7848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('HI.crfsuite')\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "\n",
    "y_pred_HI = [tagger.tag(xseq) for xseq in X_test_HI]\n",
    "\n",
    "\n",
    "print(bio_classification_report(y_test_HI, y_pred_HI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Telugu-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           #       0.82      0.56      0.67        48\n",
      "           $       0.82      0.46      0.58        68\n",
      "           @       0.91      0.89      0.90       246\n",
      "          CC       0.94      0.87      0.90        68\n",
      "          DT       0.90      0.77      0.83       123\n",
      "           E       0.93      0.80      0.86        82\n",
      "         G_J       0.85      0.65      0.73       271\n",
      "         G_N       0.70      0.82      0.76      2148\n",
      "       G_PRP       0.70      0.49      0.57       221\n",
      "       G_PRT       0.76      0.55      0.64       140\n",
      "         G_R       0.81      0.66      0.73       118\n",
      "       G_SYM       0.00      0.00      0.00        12\n",
      "         G_V       0.75      0.51      0.61       534\n",
      "         G_X       0.61      0.70      0.65      1147\n",
      "         PSP       0.75      0.62      0.68       203\n",
      "           U       0.91      0.97      0.94        70\n",
      "        null       0.08      0.02      0.04        44\n",
      "           ~       0.67      0.22      0.33         9\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      5552\n",
      "   macro avg       0.72      0.59      0.63      5552\n",
      "weighted avg       0.72      0.71      0.71      5552\n",
      " samples avg       0.71      0.71      0.71      5552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('TE.crfsuite')\n",
    "\n",
    "def bio_classification_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Classification report for a list of BIO-encoded sequences.\n",
    "    It computes token-level metrics and discards \"O\" labels.\n",
    "    \n",
    "    Note that it requires scikit-learn 0.15+ (or a version from github master)\n",
    "    to calculate averages properly!\n",
    "    \"\"\"\n",
    "    lb = LabelBinarizer()\n",
    "    y_true_combined = lb.fit_transform(list(chain.from_iterable(y_true)))\n",
    "    y_pred_combined = lb.transform(list(chain.from_iterable(y_pred)))\n",
    "        \n",
    "    tagset = set(lb.classes_) - {'O'}\n",
    "    tagset = sorted(tagset, key=lambda tag: tag.split('-', 1)[::-1])\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(lb.classes_)}\n",
    "    \n",
    "    return classification_report(\n",
    "        y_true_combined,\n",
    "        y_pred_combined,\n",
    "        labels = [class_indices[cls] for cls in tagset],\n",
    "        target_names = tagset,\n",
    "    )\n",
    "\n",
    "\n",
    "y_pred_TE = [tagger.tag(xseq) for xseq in X_test_TE]\n",
    "\n",
    "\n",
    "print(bio_classification_report(y_test_TE, y_pred_TE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
